{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef2787fb23b444393deb36d59a52e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/31509 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log = pm4py.read_xes(\"../data/BPI_Challenge_2017.xes.gz\")\n",
    "dataframe_initial = pm4py.convert_to_dataframe(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframe_initial.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Action', 'org:resource', 'concept:name', 'EventOrigin', 'EventID',\n",
       "       'lifecycle:transition', 'time:timestamp', 'case:LoanGoal',\n",
       "       'case:ApplicationType', 'case:concept:name', 'case:RequestedAmount',\n",
       "       'FirstWithdrawalAmount', 'NumberOfTerms', 'Accepted', 'MonthlyCost',\n",
       "       'Selected', 'CreditScore', 'OfferedAmount', 'OfferID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2016-01-01 09:51:15.304000+00:00\n",
       "1         2016-01-01 09:51:15.352000+00:00\n",
       "2         2016-01-01 09:51:15.774000+00:00\n",
       "3         2016-01-01 09:52:36.392000+00:00\n",
       "4         2016-01-01 09:52:36.403000+00:00\n",
       "                        ...               \n",
       "1202262   2017-01-06 06:33:02.212000+00:00\n",
       "1202263   2017-01-06 06:33:02.221000+00:00\n",
       "1202264   2017-01-16 09:51:21.114000+00:00\n",
       "1202265   2017-01-16 09:51:21.139000+00:00\n",
       "1202266   2017-01-16 09:51:21.146000+00:00\n",
       "Name: time:timestamp, Length: 1202267, dtype: datetime64[ns, UTC]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"time:timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            A_Create Application\n",
       "1                     A_Submitted\n",
       "2                  W_Handle leads\n",
       "3                  W_Handle leads\n",
       "4          W_Complete application\n",
       "                    ...          \n",
       "1202262       W_Call after offers\n",
       "1202263       W_Call after offers\n",
       "1202264               A_Cancelled\n",
       "1202265               O_Cancelled\n",
       "1202266       W_Call after offers\n",
       "Name: concept:name, Length: 1202267, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"concept:name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event_of_interest = \"A_Cancelled\"\n",
    "event_of_interest = \"O_Accepted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time until 'O_Accepted' across all cases: 26959345901.808 seconds\n",
      "Total time until 'O_Accepted' per case: 1564856.3908641746 seconds\n",
      "Which is approximately 434.68 hours or 18.11 days.\n"
     ]
    }
   ],
   "source": [
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['time:timestamp'])\n",
    "df['case_id'] = df[\"case:concept:name\"].apply(lambda x: int(x.split(\"_\")[1]))\n",
    "df[\"event_name\"] = df[\"concept:name\"]\n",
    "\n",
    "# Sort by caseID and timestamp\n",
    "df = df.sort_values(['case_id', 'timestamp'])\n",
    "\n",
    "# Get the first timestamp for each caseID\n",
    "start_times = df.groupby('case_id')['timestamp'].min().rename('start_time')\n",
    "\n",
    "# Get the \"A_Cancelled\" timestamp for each caseID\n",
    "cancelled_times = df[df['event_name'] == event_of_interest].groupby('case_id')['timestamp'].min().rename('cancelled_time')\n",
    "\n",
    "# Combine start and cancelled times\n",
    "time_df = pd.concat([start_times, cancelled_times], axis=1).dropna()\n",
    "\n",
    "# Calculate time difference\n",
    "time_df['time_until_cancelled'] = time_df['cancelled_time'] - time_df['start_time']\n",
    "\n",
    "# Convert timedelta to total seconds to avoid overflow\n",
    "time_df['time_until_cancelled_seconds'] = time_df['time_until_cancelled'].dt.total_seconds()\n",
    "\n",
    "# Total time until \"A_Cancelled\" across all cases in seconds\n",
    "total_time_seconds = time_df['time_until_cancelled_seconds'].sum()\n",
    "average_time_per_case = total_time_seconds/len(time_df)\n",
    "\n",
    "# Optionally, convert total seconds to a more readable format (e.g., hours, days)\n",
    "total_time_hours = average_time_per_case / 3600  # Convert to hours\n",
    "total_time_days = average_time_per_case / (3600 * 24)  # Convert to days\n",
    "\n",
    "print(f\"Total time until '{event_of_interest}' across all cases: {total_time_seconds} seconds\")\n",
    "print(f\"Total time until '{event_of_interest}' per case: {average_time_per_case} seconds\")\n",
    "print(f\"Which is approximately {total_time_hours:.2f} hours or {total_time_days:.2f} days.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total time until 'A_Cancelled' across all cases: 26908165328.758 seconds <br>\n",
    "Total time until 'A_Cancelled' per case: 2579634.294771163 seconds <br>\n",
    "Which is approximately 716.57 hours or 29.86 days. <br>\n",
    " <br>\n",
    "Total time until 'O_Accepted' across all cases: 26959345901.808 seconds <br>\n",
    "Total time until 'O_Accepted' per case: 1564856.3908641746 seconds <br>\n",
    "Which is approximately 434.68 hours or 18.11 days. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case_id\n",
      "235300         63\n",
      "355337         29\n",
      "438333        107\n",
      "919303         20\n",
      "1030996        35\n",
      "             ... \n",
      "2146802304     52\n",
      "2147069097     34\n",
      "2147147129     47\n",
      "2147201499     32\n",
      "2147356192     62\n",
      "Name: events_before_A_Cancelled, Length: 17228, dtype: int64\n",
      "17228\n",
      "Number of events before 'O_Accepted' for each case_id:\n",
      "case_id\n",
      "235300         63\n",
      "355337         29\n",
      "438333        107\n",
      "919303         20\n",
      "1030996        35\n",
      "             ... \n",
      "2146802304     52\n",
      "2147069097     34\n",
      "2147147129     47\n",
      "2147201499     32\n",
      "2147356192     62\n",
      "Name: events_before_A_Cancelled, Length: 17228, dtype: int64\n",
      "\n",
      "Total number of events before 'O_Accepted' across all cases: 721670\n",
      "Average number of events before 'O_Accepted' per case: 41.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20202034\\AppData\\Local\\Temp\\ipykernel_26868\\697826585.py:60: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  event_counts = df.groupby('case_id').apply(lambda group: count_events_before_cancelled(group, event_of_interest)).rename('events_before_A_Cancelled')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = dataframe_initial.copy()\n",
    "\n",
    "# Assuming you have already loaded your DataFrame 'df' with the necessary columns\n",
    "\n",
    "# Define the event of interest\n",
    "event_of_interest = \"O_Accepted\"\n",
    "\n",
    "# Step 1: Data Preparation\n",
    "# ------------------------\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['time:timestamp'])\n",
    "\n",
    "# Extract case_id from \"case:concept:name\"\n",
    "df['case_id'] = df[\"case:concept:name\"].apply(lambda x: int(x.split(\"_\")[1]))\n",
    "\n",
    "# Rename \"concept:name\" to \"event_name\" for clarity\n",
    "df[\"event_name\"] = df[\"concept:name\"]\n",
    "\n",
    "# Step 2: Sort Data\n",
    "# -----------------\n",
    "\n",
    "# Sort by case_id and timestamp to ensure chronological order within each case\n",
    "df = df.sort_values(['case_id', 'timestamp'])\n",
    "\n",
    "# Step 3: Define a Function to Count Events Before \"A_Cancelled\"\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "def count_events_before_cancelled(group, event_name):\n",
    "    \"\"\"\n",
    "    Counts the number of events that occur before the first occurrence of 'event_name' within a group.\n",
    "    \n",
    "    Parameters:\n",
    "    - group (DataFrame): The subset of the DataFrame corresponding to a single case_id.\n",
    "    - event_name (str): The name of the event to search for (e.g., \"A_Cancelled\").\n",
    "    \n",
    "    Returns:\n",
    "    - int or pd.NA: The count of events before 'event_name' or pd.NA if 'event_name' does not occur.\n",
    "    \"\"\"\n",
    "    # Reset index to ensure proper ordering\n",
    "    group = group.reset_index(drop=True)\n",
    "    \n",
    "    # Find the index of the first occurrence of 'event_name'\n",
    "    cancelled_indices = group[group['event_name'] == event_name].index\n",
    "    \n",
    "    if not cancelled_indices.empty:\n",
    "        first_cancelled_idx = cancelled_indices[0]\n",
    "        # Number of events before 'A_Cancelled' is the index of 'A_Cancelled'\n",
    "        return first_cancelled_idx\n",
    "    else:\n",
    "        # If 'A_Cancelled' does not exist, return pd.NA or another indicator\n",
    "        return pd.NA\n",
    "\n",
    "# Step 4: Apply the Function to Each Group\n",
    "# ----------------------------------------\n",
    "\n",
    "# Group the DataFrame by 'case_id' and apply the counting function\n",
    "event_counts = df.groupby('case_id').apply(lambda group: count_events_before_cancelled(group, event_of_interest)).rename('events_before_A_Cancelled')\n",
    "\n",
    "# Step 5: Handle Cases Without \"A_Cancelled\"\n",
    "# ------------------------------------------\n",
    "\n",
    "# Optionally, drop cases where 'A_Cancelled' does not occur\n",
    "event_counts = event_counts.dropna()\n",
    "\n",
    "# Convert counts to integer type (since pd.NA introduces float)\n",
    "event_counts = event_counts.astype(int)\n",
    "print(event_counts)\n",
    "\n",
    "# Step 6: Aggregate the Counts\n",
    "# ----------------------------\n",
    "\n",
    "# Total number of events before 'A_Cancelled' across all cases\n",
    "total_events_before_cancelled = event_counts.sum()\n",
    "\n",
    "# Average number of events before 'A_Cancelled' per case\n",
    "average_events_per_case = total_events_before_cancelled / len(event_counts)\n",
    "\n",
    "print(len(event_counts))\n",
    "# Step 7: Output the Results\n",
    "# --------------------------\n",
    "\n",
    "print(f\"Number of events before '{event_of_interest}' for each case_id:\")\n",
    "print(event_counts)\n",
    "\n",
    "print(f\"\\nTotal number of events before '{event_of_interest}' across all cases:\", total_events_before_cancelled)\n",
    "print(f\"Average number of events before '{event_of_interest}' per case: {average_events_per_case:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of events before 'A_Cancelled' across all cases: 239868 <br>\n",
    "Average number of events before 'A_Cancelled' per case: 23.00 <br>\n",
    " <br>\n",
    "Total number of events before 'O_Accepted' across all cases: 721670 <br>\n",
    "Average number of events before 'O_Accepted' per case: 41.89 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           Application_652823628\n",
       "1           Application_652823628\n",
       "2           Application_652823628\n",
       "3           Application_652823628\n",
       "4           Application_652823628\n",
       "                    ...          \n",
       "1202262    Application_1350494635\n",
       "1202263    Application_1350494635\n",
       "1202264    Application_1350494635\n",
       "1202265    Application_1350494635\n",
       "1202266    Application_1350494635\n",
       "Name: case:concept:name, Length: 1202267, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_initial[\"case:concept:name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events before 'A_Cancelled' for each case_id:\n",
      "case_id\n",
      "1031629108    150\n",
      "450313645     146\n",
      "2018258104    142\n",
      "773585477     127\n",
      "1631137033    124\n",
      "             ... \n",
      "228161231      10\n",
      "1781717045     10\n",
      "961957338      10\n",
      "6992306        10\n",
      "1829767138     10\n",
      "Name: count, Length: 10431, dtype: int64\n",
      "\n",
      "Total number of events before 'A_Cancelled' across all cases: 273749\n",
      "Average number of events before 'A_Cancelled' per case: 26.24\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = dataframe_initial.copy()\n",
    "\n",
    "# Assuming you have already loaded your DataFrame 'df' with the necessary columns\n",
    "\n",
    "# Define the event of interest\n",
    "event_of_interest = \"A_Cancelled\"\n",
    "\n",
    "# Step 1: Data Preparation\n",
    "# ------------------------\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['time:timestamp'])\n",
    "\n",
    "# Extract case_id from \"case:concept:name\"\n",
    "df['case_id'] = df[\"case:concept:name\"].apply(lambda x: int(x.split(\"_\")[1]))\n",
    "\n",
    "# Rename \"concept:name\" to \"event_name\" for clarity\n",
    "df[\"event_name\"] = df[\"concept:name\"]\n",
    "\n",
    "case_ids_event = df[df[\"event_name\"] == event_of_interest].case_id.tolist()\n",
    "df_event = df[df[\"case_id\"].isin(case_ids_event)]\n",
    "case_counts_event = df_event[\"case_id\"].value_counts()\n",
    "total_events_before_cancelled = case_counts_event.sum()\n",
    "\n",
    "# Average number of events before 'A_Cancelled' per case\n",
    "average_events_per_case = total_events_before_cancelled / len(case_counts_event)\n",
    "\n",
    "print(f\"Number of events before '{event_of_interest}' for each case_id:\")\n",
    "print(case_counts_event)\n",
    "\n",
    "print(f\"\\nTotal number of events before '{event_of_interest}' across all cases:\", total_events_before_cancelled)\n",
    "print(f\"Average number of events before '{event_of_interest}' per case: {average_events_per_case:.2f}\")\n",
    "\n",
    "# NOTE: NOT CORRECT, this counts complete trace length not until the event of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Least Frequent case_ids:\n",
      "        case:concept:name  count\n",
      "0   Application_419883832     10\n",
      "1   Application_523628252     10\n",
      "2   Application_104674625     10\n",
      "3  Application_1823648369     10\n",
      "4   Application_720418044     10\n",
      "5  Application_1829767138     10\n",
      "6   Application_228161231     10\n",
      "7  Application_1781717045     10\n",
      "8   Application_961957338     10\n",
      "9   Application_519478762     10\n"
     ]
    }
   ],
   "source": [
    "df = dataframe_initial.copy()\n",
    "\n",
    "# Calculate frequencies\n",
    "case_id_counts = df[\"case:concept:name\"].value_counts()\n",
    "\n",
    "# Find the 10 least frequent case_ids\n",
    "least_frequent = case_id_counts.nsmallest(10)\n",
    "\n",
    "# Convert to DataFrame\n",
    "least_frequent_df = least_frequent.reset_index()\n",
    "least_frequent_df.columns = [\"case:concept:name\", \"count\"]\n",
    "\n",
    "print(\"10 Least Frequent case_ids:\")\n",
    "print(least_frequent_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea:\n",
    "\n",
    "- since A_Cancelled takes longer 50% longer, but has on average about half of the events, the average time between events for Cancelled should be way longer, this could then be a good predictor\n",
    "- Only problem, pretty likely that all this extra time comes form only waiting for cancelled. So if this is the only extra time this does not help us a lot in the earlier events. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
